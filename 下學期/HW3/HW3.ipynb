{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "735e4762-cce9-40b7-87d2-58bb50317e6f",
   "metadata": {},
   "source": [
    "## Step1. 載入訓練資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4cee9b4f-3901-402c-b175-f2c9f9d9fca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "TRAIN_NORMAL = \"train_normal.npy\"\n",
    "TRAIN_INNER_BREAK = \"train_inner_break.npy\"\n",
    "TRAIN_OUTER_BREAK = \"train_outer_break.npy\"\n",
    "TEST_PREDICT = \"test.npy\"\n",
    "TARGET_WIDTH = 32\n",
    "TARGET_HEIGHT = 32\n",
    "TARGET_LENGTH = TARGET_WIDTH * TARGET_HEIGHT\n",
    "\n",
    "def random_crop(wave):\n",
    "    start = np.random.randint(len(wave) - TARGET_LENGTH, size=1)[0]\n",
    "    end = start + TARGET_LENGTH\n",
    "    subwave = wave[start:end]\n",
    "    return subwave\n",
    "\n",
    "def type_to_lable(val):\n",
    "    if \"normal\" in val:\n",
    "        return 0\n",
    "    if \"inner_break\" in val:\n",
    "        return 1\n",
    "    if \"outer_break\" in val:\n",
    "        return 2\n",
    "    raise Exception(\"unknown type\")\n",
    "\n",
    "def label_to_type(label):\n",
    "    return [\"normal\", \"inner_break\", \"outer_break\", \"unknown\"][label]\n",
    "\n",
    "def draw_wave(wave, label):\n",
    "    y = wave\n",
    "    x = np.arange(0, len(y), 1, dtype=int)\n",
    "    plt.plot(x, y)\n",
    "    plt.title(label_to_type(label))\n",
    "    plt.show()\n",
    "\n",
    "class WaveDatasets(Dataset):\n",
    "    def __init__(self, loading=True):\n",
    "        self._data_pair = list()\n",
    "\n",
    "        if loading:\n",
    "            for name in [TRAIN_NORMAL, TRAIN_INNER_BREAK, TRAIN_OUTER_BREAK]:\n",
    "                data = np.load(name)\n",
    "                label = type_to_lable(name)\n",
    "                for wave in data:\n",
    "                    self._data_pair.append((wave, label))\n",
    "            random.shuffle(self._data_pair)\n",
    "\n",
    "    def split(self, r=0.1):\n",
    "        wset = WaveDatasets(False)\n",
    "        size = round(len(self._data_pair) * (1. - 0.1))\n",
    "        random.shuffle(self._data_pair)\n",
    "\n",
    "        lhs = self._data_pair[:size]\n",
    "        rhs = self._data_pair[size:]\n",
    "        self._data_pair = lhs\n",
    "        wset._data_pair = rhs\n",
    "        return wset\n",
    "\n",
    "    def look(self, idx):\n",
    "        wave, label = self._data_pair[idx]\n",
    "        draw_wave(wave, label)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._data_pair)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        wave, label = self._data_pair[idx]\n",
    "        return torch.from_numpy(random_crop(wave)).float(), int(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc189ca-b341-49da-83b1-c1e4a3d6f428",
   "metadata": {},
   "source": [
    "## Step2. 架構網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87dd0aa4-47c9-4fd7-ac19-82fd85feead3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class FullyConnect(nn.Module):\n",
    "    def __init__(self, in_size,\n",
    "                       out_size,\n",
    "                       activation=None):\n",
    "        super().__init__()\n",
    "        self.act = activation\n",
    "        self.linear = nn.Linear(\n",
    "            in_size,\n",
    "            out_size,\n",
    "            bias=True\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        if not self.act is None:\n",
    "            x = self.act(x)\n",
    "        return x\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels,\n",
    "                       out_channels,\n",
    "                       kernel_size,\n",
    "                       activation=None):\n",
    "        super().__init__()\n",
    "        self.act = activation\n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            padding=\"same\",\n",
    "            bias=False,\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(\n",
    "            out_channels,\n",
    "            eps=1e-5\n",
    "        )\n",
    "        nn.init.kaiming_normal_(self.conv.weight,\n",
    "                                mode=\"fan_out\",\n",
    "                                nonlinearity=\"relu\")\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        if not self.act is None:\n",
    "            x = self.act(x)\n",
    "        return x\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        oc = 1\n",
    "        self._body = nn.Sequential(\n",
    "            ConvBlock(1, 32, 3, nn.SiLU()),\n",
    "            ConvBlock(32, 32, 3, nn.SiLU()),\n",
    "            ConvBlock(32, 1, 3, nn.SiLU())\n",
    "        )\n",
    "        self._head = nn.Sequential(\n",
    "            nn.Flatten(start_dim=1, end_dim=3),\n",
    "            FullyConnect(oc * TARGET_WIDTH * TARGET_HEIGHT, 256, nn.SiLU()),\n",
    "            FullyConnect(256, 3)\n",
    "        )\n",
    "        self._softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, n = x.shape\n",
    "        x = torch.reshape(x, (b, 1, TARGET_WIDTH, TARGET_HEIGHT))\n",
    "        x = self._body(x)\n",
    "        x = self._head(x)\n",
    "        return x\n",
    "\n",
    "    def get_max(self, x):\n",
    "        y = self.get_prob(x)\n",
    "        _, i = torch.max(y, 1)\n",
    "        return i.detach()\n",
    "\n",
    "    def get_prob(self, x):\n",
    "        y = self(x)\n",
    "        y = self._softmax(y)\n",
    "        return y.detach()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a425b452-4751-4f23-a276-321894f4af3f",
   "metadata": {},
   "source": [
    "## Step3. 訓練網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb6406fc-660d-4a7d-be3e-c17a52ee184b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoches: 10 -> loss: 0.004180, acc: 100.000000%\n",
      "epoches: 20 -> loss: 0.006735, acc: 98.666667%\n",
      "epoches: 30 -> loss: 0.006087, acc: 100.000000%\n",
      "epoches: 40 -> loss: 0.000126, acc: 100.000000%\n",
      "epoches: 50 -> loss: 0.043705, acc: 100.000000%\n",
      "epoches: 60 -> loss: 0.029624, acc: 98.666667%\n",
      "epoches: 70 -> loss: 0.004715, acc: 100.000000%\n",
      "epoches: 80 -> loss: 0.007465, acc: 100.000000%\n",
      "epoches: 90 -> loss: 0.057607, acc: 100.000000%\n",
      "epoches: 100 -> loss: 0.000709, acc: 98.666667%\n",
      "epoches: 110 -> loss: 0.005713, acc: 100.000000%\n",
      "epoches: 120 -> loss: 0.000349, acc: 100.000000%\n",
      "epoches: 130 -> loss: 0.000132, acc: 100.000000%\n",
      "epoches: 140 -> loss: 0.001699, acc: 100.000000%\n",
      "epoches: 150 -> loss: 0.000007, acc: 100.000000%\n",
      "epoches: 160 -> loss: 0.000021, acc: 100.000000%\n",
      "epoches: 170 -> loss: 0.000011, acc: 100.000000%\n",
      "epoches: 180 -> loss: 0.000168, acc: 100.000000%\n",
      "epoches: 190 -> loss: 0.000277, acc: 100.000000%\n",
      "epoches: 200 -> loss: 0.000147, acc: 100.000000%\n",
      "epoches: 210 -> loss: 0.003283, acc: 100.000000%\n",
      "epoches: 220 -> loss: 0.014882, acc: 100.000000%\n",
      "epoches: 230 -> loss: 0.000319, acc: 100.000000%\n",
      "epoches: 240 -> loss: 0.000009, acc: 100.000000%\n",
      "epoches: 250 -> loss: 0.000129, acc: 100.000000%\n",
      "epoches: 260 -> loss: 0.000037, acc: 100.000000%\n",
      "epoches: 270 -> loss: 0.001478, acc: 100.000000%\n",
      "epoches: 280 -> loss: 0.000117, acc: 100.000000%\n",
      "epoches: 290 -> loss: 0.000159, acc: 100.000000%\n",
      "epoches: 300 -> loss: 0.000048, acc: 100.000000%\n",
      "epoches: 310 -> loss: 0.000138, acc: 100.000000%\n",
      "epoches: 320 -> loss: 0.000050, acc: 100.000000%\n",
      "epoches: 330 -> loss: 0.155031, acc: 97.333333%\n",
      "epoches: 340 -> loss: 0.038715, acc: 100.000000%\n",
      "epoches: 350 -> loss: 0.012177, acc: 100.000000%\n",
      "epoches: 360 -> loss: 0.000189, acc: 100.000000%\n",
      "epoches: 370 -> loss: 0.003584, acc: 100.000000%\n",
      "epoches: 380 -> loss: 0.000006, acc: 100.000000%\n",
      "epoches: 390 -> loss: 0.000128, acc: 100.000000%\n",
      "epoches: 400 -> loss: 0.000379, acc: 100.000000%\n",
      "epoches: 410 -> loss: 0.000348, acc: 100.000000%\n",
      "epoches: 420 -> loss: 0.000807, acc: 100.000000%\n",
      "epoches: 430 -> loss: 0.000271, acc: 100.000000%\n",
      "epoches: 440 -> loss: 0.000009, acc: 98.666667%\n",
      "epoches: 450 -> loss: 0.000181, acc: 100.000000%\n",
      "epoches: 460 -> loss: 0.000040, acc: 100.000000%\n",
      "epoches: 470 -> loss: 0.000006, acc: 100.000000%\n",
      "epoches: 480 -> loss: 0.000008, acc: 100.000000%\n",
      "epoches: 490 -> loss: 0.000151, acc: 100.000000%\n",
      "epoches: 500 -> loss: 0.000013, acc: 100.000000%\n"
     ]
    }
   ],
   "source": [
    "t_set = WaveDatasets()\n",
    "v_set = t_set.split(r=0.1)\n",
    "\n",
    "t_loader = DataLoader(t_set, batch_size=128, shuffle=True)\n",
    "v_loader = DataLoader(v_set, batch_size=128, shuffle=True)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "net = Network()\n",
    "net = net.to(device)\n",
    "\n",
    "cross_entry = nn.CrossEntropyLoss()\n",
    "opt = optim.Adam(net.parameters(),\n",
    "                 lr=0.01,\n",
    "                 weight_decay=0.)\n",
    "\n",
    "for e in range(500):\n",
    "    verbose_steps = 0\n",
    "    running_loss = 0\n",
    "    for _, (waves, labels) in enumerate(t_loader):\n",
    "        net.train()\n",
    "        waves = waves.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        pred = net(waves)\n",
    "        loss = cross_entry(pred, labels)\n",
    "    \n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "        running_loss += loss.item()\n",
    "        verbose_steps += 1\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for _, (waves, labels) in enumerate(v_loader):\n",
    "        net.eval()\n",
    "        waves = waves.to(device)\n",
    "        labels = labels.to(device)\n",
    "        pred = net.get_max(waves)\n",
    "\n",
    "        correct += torch.where(labels==pred, 1, 0).sum().item()\n",
    "        total += len(labels)\n",
    "    if (e+1) % 10 == 0:\n",
    "        print(\"epoches: {} -> loss: {:.6f}, acc: {:.6f}%\".format(\n",
    "                  e+1, running_loss/verbose_steps, 100 * correct/total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c334d6-8947-4b13-9635-98460d4355e5",
   "metadata": {},
   "source": [
    "## Step4. 預測節果並輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1712b15-86b5-4816-9d42-bfbdfd9d8566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0\n",
      "0    inner_break\n",
      "1         normal\n",
      "2    inner_break\n",
      "3    outer_break\n",
      "4    outer_break\n",
      "..           ...\n",
      "235  inner_break\n",
      "236  inner_break\n",
      "237       normal\n",
      "238  inner_break\n",
      "239       normal\n",
      "\n",
      "[240 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "csv_result = str()\n",
    "net.eval()\n",
    "data = np.load(TEST_PREDICT)\n",
    "\n",
    "for idx, wave in enumerate(data):\n",
    "    subwaves = list()\n",
    "    for i in range(128):\n",
    "        subwaves.append(random_crop(wave))\n",
    "    subwaves = np.array(subwaves)\n",
    "    subwaves = torch.from_numpy(subwaves).float()\n",
    "    subwaves = subwaves.to(device)\n",
    "    pred = net.get_max(subwaves)\n",
    "\n",
    "    result = np.zeros((3))\n",
    "    for i in range(len(result)):\n",
    "        result[i] = torch.where(pred==i, 1, 0).sum().item()\n",
    "    csv_result += \"{}\\n\".format(label_to_type(np.argmax(result)))\n",
    "\n",
    "csv_result = csv_result[:-1]\n",
    "df = pd.read_csv(io.StringIO(csv_result), sep=\",\", header=None)\n",
    "print(df)\n",
    "with open(\"HW3.csv\", \"w\") as f:\n",
    "    f.write(csv_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
