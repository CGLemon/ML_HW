{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e01b83ad-2490-456a-a3e6-b72dddfdd163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob, os, io\n",
    "import math, random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "import shap\n",
    "\n",
    "class FullyConnect(nn.Module):\n",
    "    def __init__(self, in_size,\n",
    "                       out_size,\n",
    "                       act=nn.Identity):\n",
    "        super(FullyConnect, self).__init__()\n",
    "        self.act = act\n",
    "        self.linear = nn.Linear(in_size, out_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        o = self.linear(x)\n",
    "        return self.act(o)\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            FullyConnect(in_size, 512, act=nn.ReLU()),\n",
    "            FullyConnect(512, 1024, act=nn.ReLU()),\n",
    "            FullyConnect(1024, 512, act=nn.ReLU()),\n",
    "            FullyConnect(512, out_size, act=nn.ReLU())\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        o = self.layers(x)\n",
    "        return o\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x_chunk, y_chunk):\n",
    "        self.x_chunk = x_chunk\n",
    "        self.y_chunk = y_chunk\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x_chunk)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.x_chunk[idx], self.y_chunk[idx]\n",
    "        x = torch.from_numpy(x).float()\n",
    "        y = torch.from_numpy(y).float()\n",
    "        return x, y\n",
    "\n",
    "def load_all_csv():\n",
    "    train_name = os.path.join(\"kaggle\", \"train.csv\")\n",
    "    test_name = os.path.join(\"kaggle\", \"test.csv\")\n",
    "    train_df = pd.read_csv(train_name)\n",
    "    test_df = pd.read_csv(test_name)\n",
    "    return train_df, test_df\n",
    "\n",
    "def print_info(info):\n",
    "    for i, result in enumerate(info):\n",
    "        label = result[\"label\"]\n",
    "        items = result[\"items\"]\n",
    "        idx = i+1\n",
    "\n",
    "        out = str()\n",
    "        if result[\"is_obj\"]:\n",
    "            out += \"{}. {} -> {}\".format(idx, label, items)\n",
    "        else:\n",
    "            l = items[0]\n",
    "            h = items[-1]\n",
    "            out += \"{}. {} -> {}~{}\".format(idx, label,l,h)\n",
    "        if result[\"NaN\"]:\n",
    "            out += \", include {} NaN...\".format(result[\"NaN\"])\n",
    "        print(out)\n",
    "\n",
    "def get_data_format(info):\n",
    "    dformat = dict()\n",
    "\n",
    "    for result in info:\n",
    "        label = result[\"label\"]\n",
    "        if label == \"Id\":\n",
    "            continue\n",
    "\n",
    "        data = result[\"data\"]\n",
    "        items = result[\"items\"]\n",
    "        if result[\"is_obj\"]:\n",
    "            vmap = dict()\n",
    "            for i, v in enumerate(items):\n",
    "                vmap[v] = i\n",
    "            vmap[\"NaN\"] = len(items)\n",
    "            dformat[label] = {\n",
    "                \"type\" : \"one-hot\",\n",
    "                \"size\" : len(items) + 1,\n",
    "                \"map\" : vmap\n",
    "            }\n",
    "        else:\n",
    "            val_accm = 0\n",
    "            cnt = 0\n",
    "            for k, v in data.items():\n",
    "                val_accm += (k * v)\n",
    "                cnt += v\n",
    "            mean = val_accm/cnt\n",
    "            dformat[label] = {\n",
    "                \"type\" : \"scalar\",\n",
    "                \"mean\" : mean\n",
    "            }\n",
    "    return dformat\n",
    "\n",
    "def transfer_data(df, dformat):\n",
    "    labels = df.keys().values\n",
    "    x_chunk = list()\n",
    "    y_chunk = list()\n",
    "    for index, row in df.iterrows():\n",
    "        x = list()\n",
    "        y = list()\n",
    "        for label in labels:\n",
    "            if label == \"Id\":\n",
    "                continue\n",
    "            val = row[label]\n",
    "            fmt = dformat[label]\n",
    "\n",
    "            if fmt[\"type\"] == \"one-hot\":\n",
    "                if not type(val) == str and math.isnan(val):\n",
    "                    val = \"NaN\"\n",
    "                sub = [0] * fmt[\"size\"]\n",
    "                idx = fmt[\"map\"][val]\n",
    "                sub[idx] = 1\n",
    "            else:\n",
    "                if label == \"SalePrice\":\n",
    "                    sub = [val/fmt[\"mean\"]]\n",
    "                else:\n",
    "                    sub = [0] * 2\n",
    "                    if math.isnan(val):\n",
    "                        sub[0] = 1.\n",
    "                    else:\n",
    "                        sub[1] = val/fmt[\"mean\"]\n",
    "\n",
    "            if label == \"SalePrice\":\n",
    "                y.extend(sub)\n",
    "            else: \n",
    "                x.extend(sub)\n",
    "        x_chunk.append(x)\n",
    "        y_chunk.append(y)\n",
    "    x_chunk = np.array(x_chunk, dtype=np.float32)\n",
    "    y_chunk = np.array(y_chunk, dtype=np.float32)\n",
    "    return x_chunk, y_chunk\n",
    "\n",
    "def process_df_info(df):\n",
    "    labels = df.keys().values\n",
    "    info = list()\n",
    "\n",
    "    for label in labels:\n",
    "        result = {}\n",
    "        data_dict = {}\n",
    "        num_nan = 0\n",
    "\n",
    "        for v in df[label]:\n",
    "            if not type(v) == str and math.isnan(v):\n",
    "                num_nan += 1\n",
    "                continue\n",
    "\n",
    "            is_obj = type(v) == str\n",
    "            if not v in data_dict:\n",
    "                data_dict[v] = 1\n",
    "            else:\n",
    "                data_dict[v] += 1\n",
    "\n",
    "        result[\"label\"] = label\n",
    "        result[\"items\"] = sorted(list(data_dict.keys()))\n",
    "        result[\"data\"] = data_dict\n",
    "        result[\"NaN\"] = num_nan\n",
    "        result[\"is_obj\"] = is_obj\n",
    "        info.append(result)\n",
    "    return info\n",
    "\n",
    "def shuffle(x_chunk, y_chunk):\n",
    "    buf = list()\n",
    "    for x, y in zip(x_chunk, y_chunk):\n",
    "       buf.append((x,y))\n",
    "    random.shuffle(buf)\n",
    "\n",
    "    x_chunk_out, y_chunk_out = list(), list()\n",
    "    for x, y in buf:\n",
    "        x_chunk_out.append(x)\n",
    "        y_chunk_out.append(y)\n",
    "    x_chunk_out = np.array(x_chunk_out, dtype=np.float32)\n",
    "    y_chunk_out = np.array(y_chunk_out, dtype=np.float32)\n",
    "    return x_chunk_out, y_chunk_out\n",
    "\n",
    "def split(x_chunk, y_chunk, r=0.9):\n",
    "    x_chunk, y_chunk = shuffle(x_chunk, y_chunk)\n",
    "    size = round(len(y_chunk) * r) \n",
    "    train_x = x_chunk[:size]\n",
    "    train_y = y_chunk[:size]\n",
    "    test_x = x_chunk[size:]\n",
    "    test_y = y_chunk[size:]\n",
    "    return train_x, train_y, test_x, test_y\n",
    "    \n",
    "def sperate(x_chunk, features):\n",
    "    s = x_chunk.shape[0]\n",
    "    n = len(features)\n",
    "\n",
    "    x_chunk_out = np.zeros( (s, n) )\n",
    "\n",
    "    for i, x in enumerate(x_chunk):\n",
    "        for j, v in enumerate(features):\n",
    "            x_chunk_out[i][j] = x[j]\n",
    "    return x_chunk_out\n",
    "\n",
    "def test_performance(model, loader, device, dformat):\n",
    "    pred_list = np.array([], dtype=np.float32)\n",
    "    real_list = np.array([], dtype=np.float32)\n",
    "    mean = dformat[\"SalePrice\"][\"mean\"]\n",
    "\n",
    "    err, cnt = 0, 0\n",
    "    for idx, batch in enumerate(loader):\n",
    "        x, y = batch\n",
    "        x = x.to(device)\n",
    "        predict = model(x)\n",
    "\n",
    "        pred_list = np.concatenate((pred_list, np.squeeze(predict.detach().cpu().numpy(), -1)), axis=0)\n",
    "        real_list = np.concatenate((real_list, np.squeeze(y.detach().cpu().numpy(), -1)), axis=0)\n",
    "    r2 = r2_score(real_list * mean, pred_list * mean)\n",
    "    print(\"R2 score: {:.4f}\".format(r2))\n",
    "\n",
    "def print_results(model, loader, device, dformat):\n",
    "    pred_result = \"Id,SalePrice\\n\"\n",
    "    for idx, batch in enumerate(loader):\n",
    "        x, _ = batch\n",
    "        x = x.to(device)\n",
    "        predict = model(x)\n",
    "        mean = dformat[\"SalePrice\"][\"mean\"]\n",
    "        price = mean * predict.item()\n",
    "        pred_result += \"{},{:.4f}\\n\".format(idx+1461, price)\n",
    "    pred_result = pred_result[:-1]\n",
    "\n",
    "    df = pd.read_csv(io.StringIO(pred_result), sep=\",\", header=None)\n",
    "    print(df)\n",
    "\n",
    "def shap_explaine(model, x, device):\n",
    "    def model_pred(inputs):\n",
    "        pred = model(torch.from_numpy(inputs).float().to(device))\n",
    "        pred = pred.squeeze(-1)\n",
    "        pred = pred.detach().cpu().numpy()\n",
    "        return pred\n",
    "\n",
    "    x100 = shap.utils.sample(x, 100)\n",
    "    explainer = shap.Explainer(model_pred, x100)\n",
    "    shap_values = explainer(x)\n",
    "\n",
    "    accm = np.zeros(shap_values[0].values.shape)\n",
    "    cnt = 0\n",
    "    for v in shap_values:\n",
    "        accm += v.values\n",
    "        cnt += 1\n",
    "    accm /= cnt\n",
    "\n",
    "    ordered_list = list()\n",
    "    for i, val in enumerate(accm):\n",
    "        ordered_list.append((i, val))\n",
    "\n",
    "    ordered_list.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "    top_n = 5\n",
    "    best_features = list()\n",
    "\n",
    "    for i, val in ordered_list[:top_n]:\n",
    "        best_features.append(i)\n",
    "    return best_features\n",
    "\n",
    "def train(model, loader, device, learning_rate=0.001, max_steps=10000, filename=None):\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    MSE = nn.MSELoss()\n",
    "    loss_accm = 0\n",
    "\n",
    "    num_steps = 0\n",
    "    running = True\n",
    "\n",
    "    model.train()\n",
    "    while running:\n",
    "        for idx, batch in enumerate(loader):\n",
    "            x, y = batch\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            predict = model(x)\n",
    "            loss = MSE(predict, y)\n",
    "\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "            num_steps += 1\n",
    "            loss_accm += loss.item()\n",
    "            if num_steps % 100 == 0:\n",
    "                print(\"{} -> loss: {:.6f}\".format(num_steps, loss_accm/100))\n",
    "                loss_accm = 0\n",
    "            if num_steps >= max_steps:\n",
    "                running = False\n",
    "                break\n",
    "    if filename is not None:\n",
    "        torch.save(model.to(torch.device(\"cpu\")).state_dict(), filename)\n",
    "        model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a51e415-7fd2-46c0-a8fa-67c46221c1ae",
   "metadata": {},
   "source": [
    "### step 1\n",
    "預先載入所有資料，並解析資料要使用的格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46e28b68-1f7c-4a90-9b9d-6e950341a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, pred_df = load_all_csv()\n",
    "dformat = get_data_format(process_df_info(train_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d398d09f-0a50-4a10-96bd-932e2c1d91e5",
   "metadata": {},
   "source": [
    "### step 2\n",
    "準備訓練資料和測試集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89567635-56a6-40d9-86c0-4b0df026469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_chunk, y_chunk = transfer_data(train_df, dformat)\n",
    "train_x, train_y, test_x, test_y = split(x_chunk, y_chunk, r=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cc0f66-92d3-4f6b-8b78-81ef0917d922",
   "metadata": {},
   "source": [
    "### step 3\n",
    "建構模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adb1476e-411e-4355-b042-822af13bdf23",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu=True\n",
    "in_size = x_chunk.shape[1]\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "if use_gpu:\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "model = Model(in_size, 1)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a048ef3e-beeb-4bb0-8263-23012c54728b",
   "metadata": {},
   "source": [
    "### step 4\n",
    "訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1b1a94e-b0d9-4fa5-a992-b6c762c86277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 -> loss: 1.886115\n",
      "200 -> loss: 0.178639\n",
      "300 -> loss: 0.177427\n",
      "400 -> loss: 0.179152\n",
      "500 -> loss: 0.178330\n",
      "600 -> loss: 0.177267\n",
      "700 -> loss: 0.177365\n",
      "800 -> loss: 0.178128\n",
      "900 -> loss: 0.179964\n",
      "1000 -> loss: 0.178405\n",
      "1100 -> loss: 0.149821\n",
      "1200 -> loss: 0.020618\n",
      "1300 -> loss: 0.013974\n",
      "1400 -> loss: 0.012310\n",
      "1500 -> loss: 0.011965\n",
      "1600 -> loss: 0.011627\n",
      "1700 -> loss: 0.011955\n",
      "1800 -> loss: 0.011387\n",
      "1900 -> loss: 0.011218\n",
      "2000 -> loss: 0.011113\n",
      "2100 -> loss: 0.011206\n",
      "2200 -> loss: 0.011164\n",
      "2300 -> loss: 0.011913\n",
      "2400 -> loss: 0.011481\n",
      "2500 -> loss: 0.011285\n",
      "2600 -> loss: 0.011118\n",
      "2700 -> loss: 0.011158\n",
      "2800 -> loss: 0.011566\n",
      "2900 -> loss: 0.011317\n",
      "3000 -> loss: 0.011596\n",
      "3100 -> loss: 0.011748\n",
      "3200 -> loss: 0.011444\n",
      "3300 -> loss: 0.011087\n",
      "3400 -> loss: 0.011283\n",
      "3500 -> loss: 0.011519\n",
      "3600 -> loss: 0.011592\n",
      "3700 -> loss: 0.011084\n",
      "3800 -> loss: 0.011501\n",
      "3900 -> loss: 0.011303\n",
      "4000 -> loss: 0.011116\n",
      "4100 -> loss: 0.012143\n",
      "4200 -> loss: 0.010941\n",
      "4300 -> loss: 0.011099\n",
      "4400 -> loss: 0.011347\n",
      "4500 -> loss: 0.011941\n",
      "4600 -> loss: 0.011231\n",
      "4700 -> loss: 0.011519\n",
      "4800 -> loss: 0.011319\n",
      "4900 -> loss: 0.010877\n",
      "5000 -> loss: 0.011870\n",
      "5100 -> loss: 0.011174\n",
      "5200 -> loss: 0.011033\n",
      "5300 -> loss: 0.011032\n",
      "5400 -> loss: 0.011212\n",
      "5500 -> loss: 0.010730\n",
      "5600 -> loss: 0.012227\n",
      "5700 -> loss: 0.011853\n",
      "5800 -> loss: 0.011429\n",
      "5900 -> loss: 0.010946\n",
      "6000 -> loss: 0.011973\n",
      "6100 -> loss: 0.011290\n",
      "6200 -> loss: 0.011258\n",
      "6300 -> loss: 0.011149\n",
      "6400 -> loss: 0.011086\n",
      "6500 -> loss: 0.009143\n",
      "6600 -> loss: 0.008205\n",
      "6700 -> loss: 0.008038\n",
      "6800 -> loss: 0.007996\n",
      "6900 -> loss: 0.007668\n",
      "7000 -> loss: 0.007246\n",
      "7100 -> loss: 0.006991\n",
      "7200 -> loss: 0.007151\n",
      "7300 -> loss: 0.007078\n",
      "7400 -> loss: 0.006878\n",
      "7500 -> loss: 0.007759\n",
      "7600 -> loss: 0.006896\n",
      "7700 -> loss: 0.006879\n",
      "7800 -> loss: 0.006790\n",
      "7900 -> loss: 0.007208\n",
      "8000 -> loss: 0.011826\n",
      "8100 -> loss: 0.007272\n",
      "8200 -> loss: 0.006777\n",
      "8300 -> loss: 0.006687\n",
      "8400 -> loss: 0.006541\n",
      "8500 -> loss: 0.006138\n",
      "8600 -> loss: 0.006101\n",
      "8700 -> loss: 0.005973\n",
      "8800 -> loss: 0.005974\n",
      "8900 -> loss: 0.005416\n",
      "9000 -> loss: 0.005813\n",
      "9100 -> loss: 0.007091\n",
      "9200 -> loss: 0.007579\n",
      "9300 -> loss: 0.006850\n",
      "9400 -> loss: 0.006981\n",
      "9500 -> loss: 0.006883\n",
      "9600 -> loss: 0.006867\n",
      "9700 -> loss: 0.007571\n",
      "9800 -> loss: 0.006512\n",
      "9900 -> loss: 0.006880\n",
      "10000 -> loss: 0.007041\n"
     ]
    }
   ],
   "source": [
    "dataset = MyDataset(train_x, train_y)\n",
    "loader = DataLoader(dataset, batch_size=512, num_workers=4, shuffle=True)\n",
    "train(model, loader, device, 0.005, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d67182-2806-4109-be36-2de9b9f50ec7",
   "metadata": {},
   "source": [
    "### step 5\n",
    "測試模型性能，列印決定係數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a62fef4-c672-4558-8ea8-224edee8ae76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.8513\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "dataset = MyDataset(test_x, test_y)\n",
    "loader = DataLoader(dataset, batch_size=32, num_workers=1, shuffle=True)\n",
    "test_performance(model, loader, device, dformat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6395eb-912d-4f39-ab09-7caff84b2128",
   "metadata": {},
   "source": [
    "### step 6\n",
    "列印預測結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "662cbccb-0b04-426e-aff0-f47e7969f4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0            1\n",
      "0       Id    SalePrice\n",
      "1     1461  135847.5739\n",
      "2     1462       0.0000\n",
      "3     1463  183065.9100\n",
      "4     1464  191498.5818\n",
      "...    ...          ...\n",
      "1455  2915   98008.4852\n",
      "1456  2916   83054.4792\n",
      "1457  2917  171450.5240\n",
      "1458  2918  108511.6250\n",
      "1459  2919  219822.2354\n",
      "\n",
      "[1460 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "x_chunk, y_chunk = transfer_data(pred_df, dformat)\n",
    "dataset = MyDataset(x_chunk, y_chunk)\n",
    "loader = DataLoader(dataset, batch_size=1, num_workers=1, shuffle=False)\n",
    "print_results(model, loader, device, dformat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397c08fe-93f6-4707-adf8-737ba55fea64",
   "metadata": {},
   "source": [
    "### step 7\n",
    "挑選五個特徵訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c76ddc0e-31fa-43cf-8461-43717e9b2a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PermutationExplainer explainer: 1461it [01:52, 11.92it/s]                                                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 -> loss: 6.346974\n",
      "200 -> loss: 0.159189\n",
      "300 -> loss: 0.146572\n",
      "400 -> loss: 0.148056\n",
      "500 -> loss: 0.145894\n",
      "600 -> loss: 0.146655\n",
      "700 -> loss: 0.146370\n",
      "800 -> loss: 0.145295\n",
      "900 -> loss: 0.147241\n",
      "1000 -> loss: 0.144361\n",
      "1100 -> loss: 0.144011\n",
      "1200 -> loss: 0.148326\n",
      "1300 -> loss: 0.144267\n",
      "1400 -> loss: 0.145744\n",
      "1500 -> loss: 0.144227\n",
      "1600 -> loss: 0.144827\n",
      "1700 -> loss: 0.143201\n",
      "1800 -> loss: 0.144131\n",
      "1900 -> loss: 0.144705\n",
      "2000 -> loss: 0.144046\n"
     ]
    }
   ],
   "source": [
    "x_chunk, y_chunk = transfer_data(train_df, dformat)\n",
    "best_features = shap_explaine(model, x_chunk, device)\n",
    "\n",
    "model_special = Model(5, 1)\n",
    "model_special = model_special.to(device)\n",
    "\n",
    "x_chunk = sperate(x_chunk, best_features)\n",
    "train_x, train_y, test_x, test_y = split(x_chunk, y_chunk, r=0.9)\n",
    "dataset = MyDataset(train_x, train_y)\n",
    "loader = DataLoader(dataset, batch_size=512, num_workers=4, shuffle=True)\n",
    "\n",
    "train(model_special, loader, device, 0.01, 2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121a9415-7c5a-4be7-bfe8-7f27038fcb3b",
   "metadata": {},
   "source": [
    "### step 8\n",
    "測試模型性能，列印決定係數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "944d6afe-e271-4c5f-b3de-f563b17413c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score: 0.2304\n"
     ]
    }
   ],
   "source": [
    "model_special.eval()\n",
    "dataset = MyDataset(test_x, test_y)\n",
    "loader = DataLoader(dataset, batch_size=32, num_workers=1, shuffle=True)\n",
    "test_performance(model_special, loader, device, dformat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeed2548-43cf-4a4f-9cc5-d814bec4c971",
   "metadata": {},
   "source": [
    "### step 9\n",
    "列印此模型預測結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ce7ae77-59f4-4fe6-9f70-9ac58e449f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0            1\n",
      "0       Id    SalePrice\n",
      "1     1461   96398.3536\n",
      "2     1462  183591.8116\n",
      "3     1463  233919.5861\n",
      "4     1464  233919.5861\n",
      "...    ...          ...\n",
      "1455  2915  128933.9973\n",
      "1456  2916  128933.9973\n",
      "1457  2917  183591.8116\n",
      "1458  2918  145484.6821\n",
      "1459  2919  233919.5861\n",
      "\n",
      "[1460 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "x_chunk, y_chunk = transfer_data(pred_df, dformat)\n",
    "x_chunk = sperate(x_chunk, best_features)\n",
    "dataset = MyDataset(x_chunk, y_chunk)\n",
    "loader = DataLoader(dataset, batch_size=1, num_workers=1, shuffle=False)\n",
    "print_results(model_special, loader, device, dformat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
